# LAB GDG LeMans "Viens coder ton chatbot pour analyser un document avec un LLM"

üêç  approche python...

## description 

* un frontend pour l'UI du chatbot
* un backend pour la gestion des documents et le llms

utilisation du cloud Groq https://console.groq.com/ pour ex√©cuter le LLM

## installation 

### documents √† prendre en compte

ajouter les documents √† indexer dans le r√©pertoire data

### backend 

```bash
$ cd backend

# creation env virtuel
$ python3 -m venv venv-llms
$ source venv-llms/bin/activate

# installation des modules python 
$ pip install groq langchain langchain-core langchain-groq langchain-together langchain-community sentence_transformers chromadb pypdf unstructured
```

compl√©ter les API TOKEN dans le fichier config.py

```bash
# d√©marrage du serveur
$ python3 server.py
```

tester avec le playground http://localhost:5000/playground/

### frontend 

```bash
$ cd frontend

# installation des modules js 
$ npm install
```

```bash
# d√©marrage du front
$ npm start
```

tester avec http://localhost:3000


## lab 

### √©tape 1

√† partir de https://python.langchain.com/v0.2/docs/integrations/chat/groq/

comp√©ter le fichier chain.py dans le r√©pertoire backend-etape1

* penser √† compl√©ter config.py
* tester avec server.py


### √©tape 2

√† partir de https://python.langchain.com/v0.2/docs/integrations/vectorstores/chroma/#passing-a-chroma-client-into-langchain et https://docs.together.ai/docs/embeddings-python

comp√©ter le fichier chain.py dans le r√©pertoire backend-etape2

* penser √† compl√©ter config.py
* tester avec ?

### √©tape 3

√† partir de https://python.langchain.com/v0.2/docs/tutorials/retrievers/#installation et https://python.langchain.com/v0.2/docs/integrations/chat/groq/


comp√©ter le fichier chain.py dans le r√©pertoire backend-etape2

* penser √† compl√©ter config.py
* tester avec server.py
